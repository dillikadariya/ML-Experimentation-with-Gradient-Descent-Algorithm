# Prject Title: Linear Regression with Dynamic Learning Rate

This project demonstrates batch gradient descent and experiment with different values of fixed and dynamic learning rate to fit a simple linear regression model.

## Objectives
- Understand batch gradient descent optimization.
- Implement fixed and a dynamic learning rate to compare for a smoother convergence.
- Visualize model performance and training loss.

## Dataset
Synthetic data generated using a linear relationship with noise.

## Methodology
- Generate observations with a linear relationship.
- Use batch gradient descent to optimize weights.
- Dynamically adjust the learning rate for efficient training.

## Results
The model successfully fits a linear trend with minimized MSE. Based on the testing results, if the same optimal alpha(learning rate) value is chosen for both fixed and dynamic learning
rate algorithms, there isnâ€™t a substantial difference in the performance of the algorithm. This conclusion is limited by my finite testing.

